{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "import pandas as pd\n",
    "# dataset\n",
    "data = pd.read_csv(\"Market_Basket_Optimisation.csv\")\n",
    "# printing the shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "import numpy as np\n",
    "# Gather All Items of Each Transactions into Numpy Array\n",
    "transaction = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    for j in range(0, data.shape[1]):\n",
    "        transaction.append(data.values[i,j])\n",
    "# converting to numpy array\n",
    "transaction = np.array(transaction)\n",
    "#  Transform Them a Pandas DataFrame\n",
    "df = pd.DataFrame(transaction, columns=[\"items\"]) \n",
    "# Put 1 to Each Item For Making Countable Table, to be able to perform Group By\n",
    "df[\"incident_count\"] = 1 \n",
    "#  Delete NaN Items from Dataset\n",
    "indexNames = df[df['items'] == \"nan\" ].index\n",
    "df.drop(indexNames , inplace=True)\n",
    "# Making a New Appropriate Pandas DataFrame for Visualizations  \n",
    "df_table = df.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
    "#  Initial Visualizations\n",
    "df_table.head(10).style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required module\n",
    "import plotly.express as px\n",
    "# to have a same origin\n",
    "df_table[\"all\"] = \"all\" \n",
    "# creating tree map using plotly\n",
    "fig = px.treemap(df_table.head(30), path=['all', \"items\"], values='incident_count',\n",
    "                  color=df_table[\"incident_count\"].head(30), hover_data=['items'],\n",
    "                  color_continuous_scale='Greens',\n",
    "                )\n",
    "# ploting the treemap\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required module\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "# initializing the transactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transaction).transform(transaction)\n",
    "dataset = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "# dataset after encoded\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 50 items\n",
    "first50 = df_table[\"items\"].head(50).values \n",
    "# Extract Top50\n",
    "dataset = dataset.loc[:,first50] \n",
    "# shape of the dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required module\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Extracting the most frequest itemsets via Mlxtend.\n",
    "# The length column has been added to increase ease of filtering.\n",
    "frequent_itemsets = apriori(dataset, min_support=0.01, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "# printing the frequent itemset\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the frequntly items \n",
    "frequent_itemsets[ (frequent_itemsets['length'] == 2) &\n",
    "                   (frequent_itemsets['support'] >= 0.05) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the frequntly items with length 3\n",
    "frequent_itemsets[ (frequent_itemsets['length'] == 3) ].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We set our metric as \"Lift\" to define whether antecedents & consequents are dependent our not\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
    "rules[\"antecedents_length\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "rules[\"consequents_length\"] = rules[\"consequents\"].apply(lambda x: len(x))\n",
    "rules.sort_values(\"lift\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values based on confidence\n",
    "rules.sort_values(\"confidence\",ascending=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
